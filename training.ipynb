{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17312,
     "status": "ok",
     "timestamp": 1605779177203,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "fzniZ_cRx5XA",
    "outputId": "5fbdea4b-becf-4a41-d4d1-1378dcb8b76d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1605779501667,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "IhVsgtfkx6Tk",
    "outputId": "cae0bc22-f874-4f78-f2df-805e9377ef0f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/KoGPT2'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/KoGPT2\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92112,
     "status": "ok",
     "timestamp": 1605779464954,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "vHm6IQNVx6aC",
    "outputId": "b9344337-b0f9-4774-9e28-c8223df4440e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluonnlp>=0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 4.0MB/s \n",
      "\u001b[?25hCollecting mxnet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/bb/54cbabe428351c06d10903c658878d29ee7026efbe45133fd133598d6eb6/mxnet-1.7.0.post1-py2.py3-none-manylinux2014_x86_64.whl (55.0MB)\n",
      "\u001b[K     |████████████████████████████████| 55.0MB 58kB/s \n",
      "\u001b[?25hCollecting sentencepiece==0.1.90\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 57.2MB/s \n",
      "\u001b[?25hCollecting transformers==2.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
      "\u001b[K     |████████████████████████████████| 481kB 56.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.41.1)\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 57.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp>=0.8.3->-r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp>=0.8.3->-r requirements.txt (line 1)) (0.29.21)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp>=0.8.3->-r requirements.txt (line 1)) (20.4)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet->-r requirements.txt (line 2)) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->-r requirements.txt (line 4)) (3.0.12)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/31/c531a0cacd4f080e2a8b359248c2f52f4396fd5ae91a4eb7ded363c4f788/boto3-1.16.21-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 63.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->-r requirements.txt (line 4)) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 61.4MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.0.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 48.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 6)) (3.12.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp>=0.8.3->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet->-r requirements.txt (line 2)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting botocore<1.20.0,>=1.19.21\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/e7/bbf72c24d960735cf32503651941aee27daabb9c001dc06c0b8acb4db576/botocore-1.19.21-py2.py3-none-any.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 54.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1->-r requirements.txt (line 4)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1->-r requirements.txt (line 4)) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 6)) (50.3.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.21->boto3->transformers==2.4.1->-r requirements.txt (line 4)) (2.8.1)\n",
      "Building wheels for collected packages: gluonnlp, sacremoses\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp36-cp36m-linux_x86_64.whl size=588521 sha256=c563134dab1b62280a19e576d6f63de71a4f5b320d177cf94b216a8856877948\n",
      "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=16ff9f5d06fc1c6678f4f611b8a50b6cc6356ee979cd61a85db3c84ca2379ce7\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built gluonnlp sacremoses\n",
      "\u001b[31mERROR: botocore 1.19.21 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gluonnlp, graphviz, mxnet, sentencepiece, jmespath, botocore, s3transfer, boto3, sacremoses, tokenizers, transformers, tensorboardX\n",
      "  Found existing installation: graphviz 0.10.1\n",
      "    Uninstalling graphviz-0.10.1:\n",
      "      Successfully uninstalled graphviz-0.10.1\n",
      "Successfully installed boto3-1.16.21 botocore-1.19.21 gluonnlp-0.10.0 graphviz-0.8.4 jmespath-0.10.0 mxnet-1.7.0.post1 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.90 tensorboardX-2.1 tokenizers-0.0.11 transformers-2.4.1\n",
      "Processing /content/drive/MyDrive/KoGPT2\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 140553,
     "status": "ok",
     "timestamp": 1605779336697,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "4AdjG9lqEg2_",
    "outputId": "dd4021e0-1f58-4f8b-e7a5-cd84dd1c3d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.0+cu101\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8MB)\n",
      "\u001b[K     |████████████████████████████████| 703.8MB 25kB/s \n",
      "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6MB 1.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (1.18.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.7.0+cu101\n",
      "    Uninstalling torch-1.7.0+cu101:\n",
      "      Successfully uninstalled torch-1.7.0+cu101\n",
      "  Found existing installation: torchvision 0.8.1+cu101\n",
      "    Uninstalling torchvision-0.8.1+cu101:\n",
      "      Successfully uninstalled torchvision-0.8.1+cu101\n",
      "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1605747047619,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "f2DElIJzx6g6",
    "outputId": "bd343c57-b871-4ca7-f8af-45da5b3b171a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 19 00:50:47 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1605779348677,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "jMXrGN-91Zjg",
    "outputId": "8bce5ecf-0e54-4325-8e18-e0c2ea0c060b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.5.0+cu101'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1605759922345,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "kGgaDj61y3Dk",
    "outputId": "7be3d0b3-a554-4fda-e8bd-8d9b7a903a6c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1605779508242,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "Zj-VQAAQZ-OZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "from gluonnlp.data import SentencepieceTokenizer \n",
    "from kogpt2.utils import get_tokenizer\n",
    "from kogpt2.utils import download, tokenizer\n",
    "from kogpt2.model.torch_gpt2 import GPT2Config, GPT2LMHeadModel\n",
    "from kogpt2.data import Read_Dataset\n",
    "import gluonnlp\n",
    "from kogpt2.model.sample import sample_sequence\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from tensorboardX import SummaryWriter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6338,
     "status": "ok",
     "timestamp": 1605782213815,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "kNyXwfPmUFpQ",
    "outputId": "13d1fe52-81d1-42fc-e078-77641c8ced08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50000, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 다운로드\n",
    "\n",
    "pytorch_kogpt2 = {\n",
    "\t'url':\n",
    "\t'https://kobert.blob.core.windows.net/models/kogpt2/pytorch/pytorch_kogpt2_676e9bcfa7.params',\n",
    "\t'fname': 'pytorch_kogpt2_676e9bcfa7.params',\n",
    "\t'chksum': '676e9bcfa7'\n",
    "}\n",
    "\n",
    "kogpt2_config = {\n",
    "\t\"initializer_range\": 0.02,\n",
    "\t\"layer_norm_epsilon\": 1e-05,\n",
    "\t\"n_ctx\": 1024,\n",
    "\t\"n_embd\": 768,\n",
    "\t\"n_head\": 12,\n",
    "\t\"n_layer\": 12,\n",
    "\t\"n_positions\": 1024,\n",
    "\t\"vocab_size\": 50000\n",
    "}\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "\t\"\"\"Get the current gpu usage.\n",
    "\tReturns\n",
    "\t-------\n",
    "\tusage: dict\n",
    "\t\tKeys are device ids as integers.\n",
    "\t\tValues are memory usage as integers in MB.\n",
    "\t\"\"\"\n",
    "\tresult = subprocess.check_output(\n",
    "\t\t[\n",
    "\t\t\t'nvidia-smi', '--query-gpu=memory.used',\n",
    "\t\t\t'--format=csv,nounits,noheader'\n",
    "\t\t], encoding='utf-8')\n",
    "\t# Convert lines into a dictionary\n",
    "\tgpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "\tgpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "\treturn gpu_memory_map\n",
    "\n",
    "\n",
    "ctx = 'cuda' #'cuda' #'cpu' #학습 Device CPU or GPU. colab의 경우 GPU 사용\n",
    "cachedir = '~/kogpt2/' # KoGPT-2 모델 다운로드 경로\n",
    "use_cuda = True # Colab내 GPU 사용을 위한 값\n",
    "\n",
    "#시각화를 위한 툴\n",
    "#summary = SummaryWriter()\n",
    "\n",
    "# download model\n",
    "model_info = pytorch_kogpt2\n",
    "model_path = download(model_info['url'],\n",
    "              model_info['fname'],\n",
    "              model_info['chksum'],\n",
    "              cachedir=cachedir)\n",
    "# download vocab\n",
    "vocab_info = tokenizer\n",
    "vocab_path = download(vocab_info['url'],\n",
    "              vocab_info['fname'],\n",
    "              vocab_info['chksum'],\n",
    "              cachedir=cachedir)\n",
    "\n",
    "# KoGPT-2 언어 모델 학습을 위한 GPT2LMHeadModel 선언\n",
    "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
    "\n",
    "# model_path 로부터 다운로드 받은 내용을 load_state_dict 으로 업로드\n",
    "kogpt2model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "device = torch.device(ctx)\n",
    "kogpt2model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5081,
     "status": "ok",
     "timestamp": 1605780005507,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "TyC9SJFS_7R9",
    "outputId": "ae1f54a0-8cf4-4c4d-ac31-522910751f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "to_tokens: ['▁이', '▁지난', '년까지', '▁세계', '억', '명', '천만', '대', ',', '▁20', '년', '▁1', '억', '5', '천만', '대', ',', '▁20', '23', '년에는', '▁1', '억', '5', '천만', '대', '▁판매할', '▁계획이다', '▁전망했다', '.', '</s>']\n",
      "삼성전자는 2020년 1억5천만대, 2020년에는 1억6천만대, 2040년에는 1억5천만대를 판매할 것으로 예상된다.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##초기화 상태에서 문장생성\n",
    "\n",
    "kogpt2model.eval()\n",
    "\n",
    "vocab_b_obj = gluonnlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
    "                                                          mask_token=None,\n",
    "                                                          sep_token = None,\n",
    "                                                          cls_token = None,\n",
    "                                                          unknown_token='<unk>',\n",
    "                                                          padding_token='<pad>',\n",
    "                                                          bos_token='<s>',\n",
    "                                                          eos_token='</s>')\n",
    "tok_path = get_tokenizer()\n",
    "model, vocab = kogpt2model, vocab_b_obj\n",
    "sentencepieceTokenizer = SentencepieceTokenizer(tok_path)\n",
    "\n",
    "tok = SentencepieceTokenizer(tok_path)\n",
    "\n",
    "sent = sample_sequence(model.to(\"cpu\"), tok, vocab, sent=\"삼성전자는 2020년\", text_size=100, temperature=0.7, top_p=0.8, top_k=40)\n",
    "sent = sent.replace(\"<unused0>\", \"\\n\")\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1605782349909,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "AOH2YVXTUIK-"
   },
   "outputs": [],
   "source": [
    "#학습범위 조절\n",
    "epoch = 3\n",
    "\n",
    "#학습결과를 저장하는 경로\n",
    "save_path = 'checkpoint/'\n",
    "\n",
    "#생성 결과를 저장할 경로\n",
    "samples = \"samples/\"\n",
    "\n",
    "#학습할 데이터를 불러오는 경로\n",
    "data_file_path = 'dataset/'\n",
    "data_name = 'qt1_hyundaimotor.txt'\n",
    "\n",
    "#배치사이즈\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "\n",
    "#keyword_en = [\"new_product\", \"stock\", \"invest\", \"sales\", \"recruit\", \"hr\", \"culture\", \"salary\"]\n",
    "#company = 'samsung'\n",
    "#data_file_name = []\n",
    "\n",
    "#for keyword in keyword_en:\n",
    "  #data_file_name.append(f'{company}_{keyword}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 9025,
     "status": "error",
     "timestamp": 1605782360716,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "PSH_Zb-BV-nN",
    "outputId": "96910b3b-4ded-47b4-e570-b92470c1c28a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "tokenizer ending\n",
      "(413,)\n",
      "KoGPT-2 Transfer Learning Start\n",
      "epoch no.0 train no.0  loss = 4.28892 avg_loss = 4.28892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-5cab985a59af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습하기\n",
    "\n",
    "kogpt2model.train()\n",
    "\n",
    "vocab_b_obj = gluonnlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
    "                            mask_token=None,\n",
    "                            sep_token=None,\n",
    "                            cls_token=None,\n",
    "                            unknown_token='<unk>',\n",
    "                            padding_token='<pad>',\n",
    "                            bos_token='<s>',\n",
    "                            eos_token='</s>')\n",
    "\n",
    "\n",
    "tok_path = get_tokenizer()\n",
    "model, vocab = kogpt2model, vocab_b_obj\n",
    "tok = SentencepieceTokenizer(tok_path)\n",
    "\n",
    "dataset = Read_Dataset(data_file_path+data_name, vocab, tok)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "learning_rate = 3e-5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print('KoGPT-2 Transfer Learning Start')\n",
    "avg_loss = (0.0, 0.0)\n",
    "\n",
    "count = 0\n",
    "for epoch in range(epoch):\n",
    "  for data in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    data = torch.stack(data) # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n",
    "    data = data.transpose(1,0)\n",
    "    data = data.to(ctx)\n",
    "    model = model.to(ctx)\n",
    "\n",
    "    outputs = model(data, labels=data)\n",
    "    loss, logits = outputs[:2]\n",
    "    loss = loss.to(ctx)\n",
    "    loss.backward()\n",
    "    avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if count % 100 == 0:\n",
    "      print('epoch no.{0} train no.{1}  loss = {2:.5f} avg_loss = {3:.5f}' . format(epoch, count, loss, avg_loss[0] / avg_loss[1]))\n",
    "\n",
    "    count += 1\n",
    "\n",
    "  if (epoch > 0 and epoch % 5 == 0):\n",
    "\n",
    "    # generator 진행\n",
    "    sent = sample_sequence(model.to(\"cpu\"), tok, vocab, sent=\"삼성전자 신제품은\", text_size=100, temperature=0.7, top_p=0.8, top_k=40)\n",
    "    sent = sent.replace(\"<unused0>\", \"\\n\")\n",
    "    print(sent)\n",
    "\n",
    "    #txt파일저장\n",
    "    f = open(samples + data_name[:-4] + '.txt', 'a', encoding=\"utf-8\")\n",
    "    f.write('epoch no.{0} train no.{1}  loss = {2:.5f} avg_loss = {3:.5f}'.format(epoch, count, loss, avg_loss[0] / avg_loss[1]))\n",
    "    f.write('\\n')\n",
    "    f.write(sent)\n",
    "    f.write('\\n\\n')\n",
    "    f.close\n",
    "    #########################################\n",
    "\n",
    "  if (epoch > 0 and epoch % 20 == 0):\n",
    "    # 모델 저장\n",
    "    try:\n",
    "      torch.save({\n",
    "        'epoch': epoch,\n",
    "        'train_no': count,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "      }, save_path + 'KoGPT2_checkpoint_' + data_name[:-4] + '_' +str(epoch) + '_' + str(count) + '.tar')\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4282,
     "status": "ok",
     "timestamp": 1605761113447,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "5V2EDvTsmuZB",
    "outputId": "26426f34-9238-4590-c934-37c8a40018c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_tokens: ['▁이', ',', '▁출시', '갤럭시', 'S', '4’', '▁미니', '’', '는', '▁‘', '갤럭시', 'S', '4', '▁액티브', '’', '가', '▁국내', '▁시장에', '▁출시된다', '됐습니다', ',', '▁부품', '도', '▁긴장', '하다', '.', '</s>']\n",
      "삼성 신제품 ‘갤럭시S4 미니’와 ‘갤럭시S4 액티브’가 국내 시장에 출시되면서 관련 업계도 분주하다.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = sample_sequence(model.to(\"cpu\"), tok, vocab, sent=\"삼성 신제품\", text_size=100, temperature=0.7, top_p=0.8, top_k=40)\n",
    "sent = sent.replace(\"<unused0>\", \"\\n\")\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "executionInfo": {
     "elapsed": 983,
     "status": "error",
     "timestamp": 1605690621478,
     "user": {
      "displayName": "신선우",
      "photoUrl": "",
      "userId": "12897814464509233670"
     },
     "user_tz": -540
    },
    "id": "dr6wujxinnHo",
    "outputId": "c497a0db-3368-4330-b908-b24a1f86d04b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-8dfe2aebc706>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=runs\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "#시각화를 위한 툴\n",
    "tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORP1jWuWTQIC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1118kogpt2-seonwoo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
